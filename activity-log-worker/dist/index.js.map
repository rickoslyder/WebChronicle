{
  "version": 3,
  "sources": ["../node_modules/itty-router/dist/itty-router.min.mjs", "../src/auth-handler.ts", "../src/ai-processor.ts", "../src/simhash-util.ts", "../src/log-handler.ts", "../src/get-logs-handler.ts", "../src/get-summary-handler.ts", "../src/get-content-handler.ts", "../src/search-handler.ts", "../src/backfill-handler.ts", "../src/config.ts", "../src/index.ts"],
  "sourceRoot": "dist",
  "sourcesContent": ["function e({base:t=\"\",routes:n=[]}={}){return{__proto__:new Proxy({},{get:(e,a,o)=>(e,...r)=>n.push([a.toUpperCase(),RegExp(`^${(t+e).replace(/(\\/?)\\*/g,\"($1.*)?\").replace(/(\\/$)|((?<=\\/)\\/)/,\"\").replace(/:(\\w+)(\\?)?(\\.)?/g,\"$2(?<$1>[^/]+)$2$3\").replace(/\\.(?=[\\w(])/,\"\\\\.\").replace(/\\)\\.\\?\\(([^\\[]+)\\[\\^/g,\"?)\\\\.?($1(?<=\\\\.)[^\\\\.\")}/*$`),r])&&o}),routes:n,async handle(e,...r){let a,o,t=new URL(e.url);e.query=Object.fromEntries(t.searchParams);for(var[p,s,u]of n)if((p===e.method||\"ALL\"===p)&&(o=t.pathname.match(s))){e.params=o.groups;for(var c of u)if(void 0!==(a=await c(e.proxy||e,...r)))return a}}}}export default{Router:e};export{e as Router};\n", "export async function authHandler(request: Request, env: any) {\n  console.log('Auth Handler - Env Keys:', Object.keys(env || {})); // Log env keys\n  const token = request.headers.get('X-Auth-Token');\n  const expectedToken = env?.AUTH_TOKEN; // Safely access AUTH_TOKEN\n  console.log('Auth Handler - Received Token:', token);\n  console.log('Auth Handler - Expected Token:', expectedToken);\n  const valid = token === expectedToken;\n  console.log('Auth Handler - Is Valid:', valid);\n  if (!valid) {\n    console.log('Auth Handler - Unauthorized access attempt');\n    return new Response('Unauthorized', { status: 401 });\n  }\n  console.log('Auth Handler - Authorized');\n  // Return undefined instead of null, although null should also work fine with itty-router v3/v4\n  return undefined; // proceed to next\n}\n", "// Assuming env.AI is bound to the AI Gateway\n\ninterface AiResponse {\n  summary: string;\n  tags: string[];\n}\n\n/**\n * Processes text using the AI Gateway to get a summary and tags.\n */\nexport async function processTextWithAI(ai: any, textContent: string): Promise<{ summary: string, tagsJson: string } | null> {\n  if (!textContent || textContent.trim().length === 0) {\n    console.log('[AI Processor] No text content to process.');\n    return { summary: '', tagsJson: '[]' }; // Return empty if no text\n  }\n\n  // Truncate very long text to avoid hitting model limits unexpectedly\n  const MAX_TEXT_LENGTH = 15000; // Adjust as needed\n  const truncatedText = textContent.length > MAX_TEXT_LENGTH\n    ? textContent.slice(0, MAX_TEXT_LENGTH)\n    : textContent;\n\n  const prompt = `Given the following web page text content, provide a concise one-paragraph summary and suggest 2-7 relevant topic tags as a JSON array of strings.\n\nRespond ONLY with a JSON object containing two keys: \"summary\" (string) and \"tags\" (JSON array of strings).\n\nExample Response Format:\n{\n  \"summary\": \"A concise summary of the text.\",\n  \"tags\": [\"tag1\", \"tag2\", \"tag3\"]\n}\n\nText Content:\n---\n${truncatedText}\n---\n\nJSON Response:`;\n\n  try {\n    console.log('[AI Processor] Sending request to AI Gateway...');\n    // Note: The specific model is usually configured in the Gateway itself or part of the URL binding.\n    // If using the generic URL like the one set in wrangler.toml, you might need to append the model name.\n    // Let's assume the Gateway URL correctly routes to @cf/meta/llama-4-scout-17b-16e-instruct\n    // The model returns the JSON string inside a 'response' field.\n    const rawAiResult = await ai.run('@cf/meta/llama-4-scout-17b-16e-instruct', { prompt });\n\n    console.log('[AI Processor] Received AI response.');\n\n    // Extract and parse the JSON string from the 'response' field\n    let parsedResponse: AiResponse | null = null;\n    if (rawAiResult && typeof rawAiResult.response === 'string') {\n      try {\n        parsedResponse = JSON.parse(rawAiResult.response.trim());\n        console.log('[AI Processor] Successfully parsed AI response JSON.');\n      } catch (parseError) {\n        console.error('[AI Processor] Failed to parse JSON from AI response:', parseError);\n        console.error('[AI Processor] Raw AI response string:', rawAiResult.response);\n      }\n    } else {\n      console.error('[AI Processor] AI raw result did not contain a response string:', rawAiResult);\n    }\n\n    // Validate the *parsed* response structure\n    if (parsedResponse && typeof parsedResponse.summary === 'string' && Array.isArray(parsedResponse.tags)) {\n      // Ensure tags are strings\n      const validTags = parsedResponse.tags.filter((tag: any) => typeof tag === 'string');\n      return {\n        summary: parsedResponse.summary.trim(),\n        tagsJson: JSON.stringify(validTags) // Store tags as JSON string\n      };\n    } else {\n      console.error('[AI Processor] Parsed AI response has unexpected format or parsing failed:', parsedResponse);\n      // Fallback: return the raw text as summary and empty tags\n      return { summary: truncatedText.slice(0, 200) + '... (AI processing failed)', tagsJson: '[]' };\n    }\n\n  } catch (error) {\n    console.error('[AI Processor] Error calling AI Gateway:', error);\n    // Fallback on error\n    return { summary: truncatedText.slice(0, 200) + '... (AI processing error)', tagsJson: '[]' };\n  }\n}\n\n/**\n * Generates a vector embedding for the given text using the AI Gateway.\n */\nexport async function generateEmbedding(ai: any, textInput: string): Promise<number[] | null> {\n  if (!textInput || textInput.trim().length === 0) {\n    console.log('[AI Processor - Embedding] No text content to generate embedding for.');\n    return null;\n  }\n\n  // Embedding models have token limits. bge-small-en-v1.5 has a max sequence length of 512 tokens.\n  // A simple character limit can act as a safeguard. Average 4 chars/token. 512*4 = 2048.\n  const MAX_EMBEDDING_TEXT_LENGTH = 2000; // Keep it slightly under the theoretical max character count\n  const text = textInput.length > MAX_EMBEDDING_TEXT_LENGTH\n    ? textInput.slice(0, MAX_EMBEDDING_TEXT_LENGTH)\n    : textInput;\n\n  try {\n    console.log(`[AI Processor - Embedding] Requesting embedding for text (original length: ${textInput.length}, effective length: ${text.length}).`);\n    const model = '@cf/baai/bge-small-en-v1.5';\n    const response = await ai.run(model, { text });\n\n    // Expected response structure: { shape: [number_of_inputs, dimensions], data: [ [embedding_vector_for_input1], ... ] }\n    if (response && response.data && Array.isArray(response.data) && response.data.length > 0 &&\n        Array.isArray(response.data[0]) && response.data[0].length > 0) {\n      console.log(`[AI Processor - Embedding] Successfully generated embedding. Dimensions: ${response.data[0].length}`);\n      return response.data[0]; // Return the first (and only) embedding vector\n    } else {\n      console.error('[AI Processor - Embedding] Failed to generate embedding or AI response format is unexpected.');\n      // Log the raw response for debugging, careful with large responses in production logs\n      try {\n        console.error('[AI Processor - Embedding] Raw AI response:', JSON.stringify(response).slice(0, 500));\n      } catch (e) {\n        console.error('[AI Processor - Embedding] Raw AI response (unstringifiable):', response);\n      }\n      return null;\n    }\n  } catch (error) {\n    console.error('[AI Processor - Embedding] Error calling AI Gateway for embedding:', error);\n    return null;\n  }\n}\n", "// Vendorized code from simhash-js (MIT License)\n// Original: https://github.com/vkandy/simhash-js\n\n// --- Jenkins.js content ---\nclass JenkinsInternal {\n    pc: number = 0;\n    pb: number = 0;\n\n    // Implementation of lookup3 algorithm\n    private lookup3(k: string, pc: number, pb: number): { c: number, b: number } {\n        let length = k.length;\n        let a: number, b: number, c: number;\n\n        a = b = c = 0xdeadbeef + length + pc;\n        c += pb;\n\n        let offset = 0;\n        while (length > 12) {\n            a += k.charCodeAt(offset + 0);\n            a += k.charCodeAt(offset + 1) << 8;\n            a += k.charCodeAt(offset + 2) << 16;\n            a += k.charCodeAt(offset + 3) << 24;\n\n            b += k.charCodeAt(offset + 4);\n            b += k.charCodeAt(offset + 5) << 8;\n            b += k.charCodeAt(offset + 6) << 16;\n            b += k.charCodeAt(offset + 7) << 24;\n\n            c += k.charCodeAt(offset + 8);\n            c += k.charCodeAt(offset + 9) << 8;\n            c += k.charCodeAt(offset + 10) << 16;\n            c += k.charCodeAt(offset + 11) << 24;\n\n            const mixed = this.mix(a, b, c);\n            a = mixed.a;\n            b = mixed.b;\n            c = mixed.c;\n\n            length -= 12;\n            offset += 12;\n        }\n\n        switch (length) { // Handle remaining bytes\n            case 12: c += k.charCodeAt(offset + 11) << 24; // Fall through\n            case 11: c += k.charCodeAt(offset + 10) << 16; // Fall through\n            case 10: c += k.charCodeAt(offset + 9) << 8;    // Fall through\n            case 9: c += k.charCodeAt(offset + 8);       // Fall through\n            case 8: b += k.charCodeAt(offset + 7) << 24; // Fall through\n            case 7: b += k.charCodeAt(offset + 6) << 16; // Fall through\n            case 6: b += k.charCodeAt(offset + 5) << 8;  // Fall through\n            case 5: b += k.charCodeAt(offset + 4);       // Fall through\n            case 4: a += k.charCodeAt(offset + 3) << 24; // Fall through\n            case 3: a += k.charCodeAt(offset + 2) << 16; // Fall through\n            case 2: a += k.charCodeAt(offset + 1) << 8;  // Fall through\n            case 1: a += k.charCodeAt(offset + 0);       // Fall through\n                break;\n            case 0: return { c: c >>> 0, b: b >>> 0 };\n        }\n\n        const finalMixed = this.finalMix(a, b, c);\n        a = finalMixed.a;\n        b = finalMixed.b;\n        c = finalMixed.c;\n\n        return { c: c >>> 0, b: b >>> 0 };\n    }\n\n    // Mixes 3 32-bit integers reversibly but fast\n    private mix(a: number, b: number, c: number): { a: number, b: number, c: number } {\n        a -= c; a ^= this.rot(c, 4); c += b;\n        b -= a; b ^= this.rot(a, 6); a += c;\n        c -= b; c ^= this.rot(b, 8); b += a;\n        a -= c; a ^= this.rot(c, 16); c += b;\n        b -= a; b ^= this.rot(a, 19); a += c;\n        c -= b; c ^= this.rot(b, 4); b += a;\n        return { a: a, b: b, c: c };\n    }\n\n    // Final mixing of 3 32-bit values (a,b,c) into c\n    private finalMix(a: number, b: number, c: number): { a: number, b: number, c: number } {\n        c ^= b; c -= this.rot(b, 14);\n        a ^= c; a -= this.rot(c, 11);\n        b ^= a; b -= this.rot(a, 25);\n        c ^= b; c -= this.rot(b, 16);\n        a ^= c; a -= this.rot(c, 4);\n        b ^= a; b -= this.rot(a, 14);\n        c ^= b; c -= this.rot(b, 24);\n        return { a: a, b: b, c: c };\n    }\n\n    // Rotate x by k distance\n    private rot(x: number, k: number): number {\n        return (((x) << (k)) | ((x) >>> (32 - (k))));\n    }\n\n    // Public hash function\n    public hash32(msg: string): number {\n        const h = this.lookup3(msg, this.pc, this.pb);\n        return h.c; // Return the number directly\n    }\n}\n\n// --- SimHash.js content ---\ninterface SimHashOptions {\n    kshingles?: number;\n    maxFeatures?: number;\n}\n\nexport class SimHash {\n    private kshingles: number;\n    private maxFeatures: number;\n    private jenkins: JenkinsInternal;\n\n    constructor(options?: SimHashOptions) {\n        this.kshingles = options?.kshingles ?? 4;\n        this.maxFeatures = options?.maxFeatures ?? 128;\n        this.jenkins = new JenkinsInternal(); // Use the internal Jenkins class\n    }\n\n    // Tokenizes input into 'kshingles' number of tokens.\n    private tokenize(original: string): string[] {\n        const size = original.length;\n        if (size <= this.kshingles) {\n            return [original];\n        }\n        const shingles: string[] = [];\n        for (let i = 0; i < size; i = i + this.kshingles) {\n            shingles.push(i + this.kshingles < size ? original.slice(i, i + this.kshingles) : original.slice(i));\n        }\n        return shingles;\n    }\n\n    // Combine shingles\n    private combineShingles(shingles: number[]): number {\n        if (shingles.length === 0) return 0; // Return 0 for empty input\n        if (shingles.length === 1) return shingles[0];\n\n        // Sort and keep top N features (hashes)\n        shingles.sort((a, b) => a - b); // Simple number sort\n        if (shingles.length > this.maxFeatures) {\n            shingles = shingles.slice(0, this.maxFeatures); // Keep the smallest hashes\n        }\n\n        let simhash = 0;\n        for (let pos = 0; pos < 32; pos++) {\n            let weight = 0;\n            const mask = 1 << pos;\n            for (const shingle of shingles) {\n                 // Check if the bit at pos is set\n                weight += (shingle & mask) !== 0 ? 1 : -1;\n            }\n            if (weight > 0) {\n                simhash |= mask; // Set the bit if weight is positive\n            }\n        }\n        return simhash >>> 0; // Ensure unsigned 32-bit integer\n    }\n\n    // Driver function.\n    public hash(input: string): number { // Returns a 32-bit unsigned number\n        const tokens = this.tokenize(input);\n        const shingles: number[] = tokens.map(token => this.jenkins.hash32(token));\n        const combinedHash = this.combineShingles(shingles);\n        return combinedHash;\n    }\n}\n\n// --- Comparator.js content ---\nexport class Comparator {\n    // Calculates binary hamming distance of two base 16 integers (strings).\n    static hammingDistance(x: string, y: string): number {\n        // Note: The original library's implementation here seems overly complex\n        // and possibly incorrect for standard Hamming distance on hex strings representing ints.\n        // Let's use a simpler, standard approach for comparing the 32-bit numbers represented by the hex strings.\n        try {\n            const n1 = parseInt(x, 16);\n            const n2 = parseInt(y, 16);\n\n            if (isNaN(n1) || isNaN(n2)) {\n                console.error(\"Invalid hex string for Hamming distance:\", x, y);\n                return 32; // Max distance for 32 bits on error\n            }\n\n            let xorResult = n1 ^ n2;\n            let distance = 0;\n            while (xorResult > 0) {\n                distance++;\n                xorResult &= (xorResult - 1); // Clear the least significant set bit\n            }\n            return distance;\n        } catch (e) {\n             console.error(\"Error calculating Hamming distance:\", e);\n             return 32; // Max distance on error\n        }\n    }\n\n    // Calculates bit-wise similarity - Jaccard index (on hex strings).\n    static similarity(x: string, y: string): number {\n         try {\n            const n1 = parseInt(x, 16);\n            const n2 = parseInt(y, 16);\n            if (isNaN(n1) || isNaN(n2)) return 0;\n\n            const intersection = n1 & n2;\n            const union = n1 | n2;\n\n            const intersectionWeight = this.hammingWeight(intersection);\n            const unionWeight = this.hammingWeight(union);\n\n            return unionWeight === 0 ? 1 : intersectionWeight / unionWeight; // Avoid division by zero\n         } catch(e) {\n            return 0;\n         }\n    }\n\n    // Calculates Hamming weight (population count) of a number.\n    static hammingWeight(n: number): number {\n        let count = 0;\n        while (n > 0) {\n            n &= (n - 1); // Clear the least significant set bit\n            count++;\n        }\n        return count;\n    }\n}\n\n", "/// <reference types=\"@cloudflare/workers-types\" />\n\nimport { processTextWithAI, generateEmbedding } from './ai-processor';\nimport type { LogDataPayload, Env } from './types';\nimport { SimHash, Comparator } from './simhash-util';\n\n// Helper function to convert ArrayBuffer to hex string (for SHA-256 hash)\nasync function bufferToHex(buffer: ArrayBuffer): Promise<string> {\n  const hashArray = Array.from(new Uint8Array(buffer));\n  const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');\n  return hashHex;\n}\n\n// Function to calculate SHA-256 hash of text\nasync function calculateHash(text: string): Promise<string> {\n  const encoder = new TextEncoder();\n  const data = encoder.encode(text);\n  const hashBuffer = await crypto.subtle.digest('SHA-256', data);\n  return bufferToHex(hashBuffer);\n}\n\n// Define Simhash threshold (adjust as needed)\nconst SIMHASH_THRESHOLD = 10;\n\nexport async function logHandler(request: Request, env: Env) {\n  let logData: (LogDataPayload & { id: string, processedAt: number }) | null = null; // Add id/processedAt, init to null\n\n  try {\n    const receivedData: Omit<LogDataPayload, 'id' | 'processedAt'> & { id?: string, processedAt?: number } = await request.json();\n    console.log('[Log Handler] Received Data:', JSON.stringify(receivedData).slice(0, 200) + '...'); // Log truncated\n\n    // Validate required fields from extension\n    const missingFields = [];\n    if (!receivedData.url) missingFields.push('url');\n    if (!receivedData.startTimestamp) missingFields.push('startTimestamp');\n    if (!receivedData.textContent) missingFields.push('textContent');\n    \n    if (missingFields.length > 0) {\n      console.error('[Log Handler] Bad Request - Missing required fields:', missingFields);\n      console.error('[Log Handler] Received fields:', Object.keys(receivedData));\n      return new Response(`Bad Request: Missing required fields: ${missingFields.join(', ')}`, { status: 400 });\n    }\n\n    // Add server-side generated fields\n    logData = {\n      ...receivedData,\n      id: receivedData.id || crypto.randomUUID(), // Use extension ID or generate new one\n      processedAt: Date.now()\n    };\n\n    console.log(`[Log Handler] Processing log ID: ${logData.id}`);\n\n    // --- Deduplication Logic --- \n    const contentHash = await calculateHash(logData.textContent);\n    console.log(`[Log Handler] Calculated content hash: ${contentHash} for log ID: ${logData.id}`);\n\n    const checkStmt = env.ACTIVITY_LOG_DB.prepare(\n      `SELECT id FROM logs WHERE contentHash = ?1 LIMIT 1`\n    ).bind(contentHash);\n    \n    const existingLog = await checkStmt.first();\n\n    if (existingLog) {\n      console.log(`[Log Handler] Duplicate content hash found (existing log ID: ${existingLog.id}). Skipping processing for new log ID: ${logData.id}.`);\n      // Optionally, update the timestamp of the existing log here\n      return new Response(JSON.stringify({ message: 'Duplicate content, skipped processing.', existingLogId: existingLog.id }), {\n        status: 200, // Or 202 Accepted, or maybe even 409 Conflict?\n        headers: { 'Content-Type': 'application/json' }\n      });\n    }\n    // --- End Deduplication Logic ---\n\n    // --- Simhash Check ---\n    const simHasher = new SimHash(); // Use default options (kshingles=4, maxFeatures=128)\n    const newSimhashInt = simHasher.hash(logData.textContent); // Returns a 32-bit unsigned number\n    const newSimhashString = newSimhashInt.toString(16).padStart(8, '0'); // Convert to 8-char hex string for storage/comparison\n\n    const previousLogStmt = env.ACTIVITY_LOG_DB.prepare(\n      'SELECT id, contentSimhash FROM logs WHERE url = ? ORDER BY endTimestamp DESC LIMIT 1'\n    );\n    const previousLog = await previousLogStmt.bind(logData.url).first<{ id: string; contentSimhash: string | null }>();\n\n    if (previousLog?.contentSimhash) {\n      try {\n        const previousSimhashString = previousLog.contentSimhash; // Already stored as hex\n        const distance = Comparator.hammingDistance(newSimhashString, previousSimhashString);\n\n        console.log(`[Log Handler] URL: ${logData.url}, New Simhash: ${newSimhashString}, Prev Simhash: ${previousLog.contentSimhash}, Distance: ${distance}`);\n\n        if (distance <= SIMHASH_THRESHOLD) {\n          console.log(`[Log Handler] Simhash duplicate detected for URL ${logData.url} (Distance: ${distance}). Skipping insert.`);\n          // Option B: Simply skip insert for now\n          return new Response('Log received (Simhash duplicate detected).', { status: 200 });\n          // TODO: Optionally implement Option A: Update existing log's endTimestamp\n        }\n      } catch (simhashError) {\n        console.error(`[Log Handler] Error during Simhash comparison for URL ${logData.url}:`, simhashError);\n        // Proceed with insert on comparison error\n      }\n    }\n    // --- End Simhash Check ---\n\n    // 1. Process with AI\n    let aiResult = await processTextWithAI(env.AI, logData.textContent);\n    if (!aiResult) {\n      // Error logged within processTextWithAI, use fallback values\n      console.warn(`[Log Handler] AI processing failed for log ID: ${logData.id}. Using fallback.`);\n      // Use truncated text as summary, empty tags\n      aiResult = { summary: logData.textContent.slice(0, 200) + '... (AI processing failed)', tagsJson: '[]' };\n    }\n    const { summary, tagsJson } = aiResult;\n\n    // 2. Store summary in R2\n    const summaryR2Key = `${logData.id}-summary.txt`;\n    console.log(`[Log Handler] Storing summary in R2 with key: ${summaryR2Key}`);\n    try {\n      await env.ACTIVITY_SUMMARIES_BUCKET.put(summaryR2Key, summary);\n      console.log(`[Log Handler] Successfully stored summary in R2 for log ID: ${logData.id}`);\n    } catch (r2Error) {\n      console.error(`[Log Handler] Failed to store SUMMARY in R2 for log ID: ${logData.id}:`, r2Error);\n      // Potentially return an error response, or just continue without summary?\n      // For now, log and continue\n    }\n\n    // 3. Store full text content in R2\n    const contentR2Key = `${logData.id}-content.txt`;\n    try {\n      await env.ACTIVITY_SUMMARIES_BUCKET.put(contentR2Key, logData.textContent);\n      console.log(`[Log Handler] Successfully stored content in R2 for log ID: ${logData.id}`);\n    } catch (err) {\n      console.error(`[Log Handler] Failed to store CONTENT in R2 for log ID: ${logData.id}:`, err);\n      // If content fails to store, we probably shouldn't proceed with D1 insert\n      return new Response('Failed to store essential content data in R2', { status: 500 });\n    }\n\n    // 4. Store metadata in D1\n    console.log(`[Log Handler] Storing metadata in D1 for log ID: ${logData.id}`);\n    const stmt = env.ACTIVITY_LOG_DB.prepare(\n      `INSERT INTO logs (id, url, title, startTimestamp, endTimestamp, timeSpentSeconds, maxScrollPercent, tagsJson, summaryR2Key, contentR2Key, processedAt, contentHash, contentSimhash)\n         VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13)`\n    );\n\n    try {\n      const d1Result = await stmt.bind(\n        logData.id,\n        logData.url,\n        logData.title || null, // Handle optional title\n        logData.startTimestamp,\n        logData.endTimestamp || null, // Handle optional endTimestamp\n        logData.timeSpentSeconds || null, // Handle optional timeSpentSeconds\n        logData.maxScrollPercent || 0, // Default to 0 if missing\n        tagsJson,\n        summaryR2Key,\n        contentR2Key,\n        logData.processedAt,\n        contentHash,\n        newSimhashString // Store the new Simhash\n      ).run();\n\n      if (d1Result.success) {\n        console.log(`[Log Handler] Successfully stored metadata in D1 for log ID: ${logData.id}`);\n\n        // --- Vectorize Embedding and Insertion ---\n        if (summary && summary.trim() !== '' && !summary.includes('(AI processing failed)') && !summary.includes('(AI processing error)')) {\n            try {\n                console.log(`[Log Handler - Vectorize] Generating embedding for summary of log ID: ${logData.id}`);\n                const embeddingVector = await generateEmbedding(env.AI, summary);\n\n                if (embeddingVector) {\n                    console.log(`[Log Handler - Vectorize] Embedding generated for log ID: ${logData.id}. Dimensions: ${embeddingVector.length}`);\n                    const vectorToUpsert = {\n                        id: logData.id, // Use the D1 log ID as the vector ID\n                        values: embeddingVector,\n                        // metadata: { url: logData.url, title: logData.title } // Optional: add metadata if needed later\n                    };\n                    await env.VECTORIZE.upsert([vectorToUpsert]);\n                    console.log(`[Log Handler - Vectorize] Successfully upserted vector for log ID: ${logData.id} into Vectorize index.`);\n                } else {\n                    console.warn(`[Log Handler - Vectorize] Embedding generation returned null for log ID: ${logData.id}. Skipping Vectorize upsert.`);\n                }\n            } catch (vectorizeError) {\n                console.error(`[Log Handler - Vectorize] Error during embedding generation or Vectorize upsert for log ID: ${logData.id}:`, vectorizeError);\n                // Non-critical error for the main log processing. Log and continue.\n            }\n        } else {\n            console.log(`[Log Handler - Vectorize] Skipping embedding for log ID: ${logData.id} due to empty, placeholder, or error summary.`);\n        }\n        // --- End Vectorize Embedding and Insertion ---\n\n        return new Response(JSON.stringify({ message: 'Log received and processed.', logId: logData.id }), { \n          status: 201, \n          headers: { 'Content-Type': 'application/json' }\n        }); // 201 Created\n      } else {\n        console.error(`[Log Handler] D1 Insert failed for log ID: ${logData.id}`, d1Result.error);\n        // Attempt to clean up R2 object if D1 fails? Maybe not necessary.\n        return new Response('Failed to store log metadata', { status: 500 });\n      }\n    } catch (d1Error) {\n      console.error(`[Log Handler] D1 Bind/Run error for log ID: ${logData.id}`, d1Error);\n      return new Response('Database error', { status: 500 });\n    }\n\n  } catch (err: any) {\n    if (err instanceof SyntaxError) {\n      console.error('[Log Handler] Invalid JSON received:', err);\n      return new Response('Invalid JSON', { status: 400 });\n    }\n    console.error('[Log Handler] Unhandled error in /log handler:', err);\n    // Add logData id to error if available\n    const logId = logData ? logData.id : 'unknown';\n    console.error(`[Log Handler] Error occurred processing log ID: ${logId}`);\n    return new Response('Internal Server Error', { status: 500 });\n  }\n}\n", "// No need to import Request, use the global one from workers-types\nimport { Env } from './types';\n\nexport async function getLogsHandler(_request: Request, env: Env): Promise<Response> {\n  console.log('[Get Logs Handler] Received request');\n\n  try {\n    const stmt = env.ACTIVITY_LOG_DB.prepare(\n      `SELECT id, url, title, startTimestamp, timeSpentSeconds, maxScrollPercent, tagsJson, processedAt\n       FROM logs\n       ORDER BY startTimestamp DESC\n       LIMIT 20`\n    );\n\n    const { results } = await stmt.all();\n\n    return new Response(JSON.stringify({ logs: results }), {\n      headers: { 'Content-Type': 'application/json' },\n      status: 200,\n    });\n\n  } catch (error) {\n    console.error('[Get Logs Handler] Error fetching logs:', error);\n    return new Response('Error fetching logs', { status: 500 });\n  }\n}\n", "// No need to import Request, use the global one from workers-types\nimport { Request } from 'itty-router'; // Use the Request type exported by itty-router\nimport { Env } from './types';\n\nexport async function getSummaryHandler(request: Request, env: Env): Promise<Response> {\n  const logId = request.params?.id;\n  console.log(`[Get Summary Handler] Received request for log ID: ${logId}`);\n\n  if (!logId) {\n    return new Response('Missing log ID parameter', { status: 400 });\n  }\n\n  try {\n    const summaryKey = `${logId}-summary.txt`; // Construct the R2 key\n\n    console.log(`[Get Summary Handler] Attempting to get key: ${summaryKey} from R2 bucket: ${env.ACTIVITY_SUMMARIES_BUCKET}`);\n    const summaryObject = await env.ACTIVITY_SUMMARIES_BUCKET.get(summaryKey);\n\n    if (summaryObject === null) {\n      console.warn(`[Get Summary Handler] Summary not found in R2 for key: ${summaryKey}`);\n      return new Response(JSON.stringify({ error: 'Summary not found' }), {\n        headers: { 'Content-Type': 'application/json' },\n        status: 404,\n      });\n    }\n\n    console.log(`[Get Summary Handler] Successfully retrieved summary for key: ${summaryKey}`);\n\n    // Assuming the summary is stored as plain text\n    const summaryText = await summaryObject.text();\n\n    return new Response(JSON.stringify({ summary: summaryText }), {\n      headers: { 'Content-Type': 'application/json' },\n      status: 200,\n    });\n\n  } catch (error) {\n    console.error(`[Get Summary Handler] Error fetching summary for log ID ${logId}:`, error);\n    return new Response('Error fetching summary', { status: 500 });\n  }\n}\n", "import { Env } from './types';\n\nexport async function getContentHandler(request: Request, env: Env): Promise<Response> {\n  const logId = (request as any).params?.id;\n\n  if (!logId) {\n    return new Response('Missing log ID in request path.', { status: 400 });\n  }\n\n  console.log(`[Get Content Handler] Received request for log ID: ${logId}`);\n\n  // Construct the R2 key used for storing the content\n  const contentKey = `${logId}-content.txt`;\n\n  try {\n    console.log(`[Get Content Handler] Attempting to get key: ${contentKey} from R2 bucket: ${env.ACTIVITY_SUMMARIES_BUCKET}`);\n    const r2Object = await env.ACTIVITY_SUMMARIES_BUCKET.get(contentKey);\n\n    if (r2Object === null) {\n      console.log(`[Get Content Handler] Content not found for key: ${contentKey}`);\n      return new Response('Content not found for the specified log ID.', { status: 404 });\n    }\n\n    console.log(`[Get Content Handler] Successfully retrieved content for key: ${contentKey}`);\n\n    // Return the content directly\n    // Set appropriate content type, assuming plain text for now\n    const headers = new Headers({\n      'Content-Type': 'text/plain; charset=utf-8',\n      // Add cache control headers if desired\n      // 'Cache-Control': 'public, max-age=3600' // Example: Cache for 1 hour\n    });\n    return new Response(r2Object.body, { headers: headers, status: 200 });\n\n  } catch (err) {\n    console.error(`[Get Content Handler] Error retrieving content from R2 for key ${contentKey}:`, err);\n    return new Response('Failed to retrieve content due to an internal error.', { status: 500 });\n  }\n}\n", "/// <reference types=\"@cloudflare/workers-types\" />\n\nimport { generateEmbedding } from './ai-processor';\nimport type { Env, LogDataPayload } from './types'; // Assuming LogDataPayload might be useful for result structure\n\ninterface SearchQueryPayload {\n  query: string;\n  topK?: number;\n}\n\n// Define a type for the items returned in search results\ninterface SearchResultItem extends Omit<LogDataPayload, 'textContent'> {\n  id: string; // Ensure id is part of the result\n  summary?: string; // We'll try to fetch this if available\n  score?: number; // Similarity score from Vectorize\n  tagsJson?: string; // Include tags if available\n  processedAt: number; // Ensure processedAt is part of the result\n  summaryR2Key?: string | null; // Field from D1 for the R2 summary object key\n  // Omit textContent to keep payload smaller, client can fetch if needed\n}\n\n\nexport async function searchHandler(request: Request, env: Env): Promise<Response> {\n  if (request.method !== 'POST') {\n    return new Response('Method Not Allowed', { status: 405 });\n  }\n\n  let payload: SearchQueryPayload;\n  try {\n    payload = await request.json();\n  } catch (e) {\n    return new Response('Invalid JSON payload', { status: 400 });\n  }\n\n  const { query, topK = 10 } = payload;\n\n  if (!query || typeof query !== 'string' || query.trim().length === 0) {\n    return new Response('Search query is missing or empty', { status: 400 });\n  }\n\n  console.log(`[Search Handler] Received search query: \"${query}\", topK: ${topK}`);\n\n  // 1. Generate embedding for the search query\n  let queryEmbedding: number[] | null;\n  try {\n    console.log(`[Search Handler] Generating embedding for query: \"${query}\"`);\n    queryEmbedding = await generateEmbedding(env.AI, query);\n    if (!queryEmbedding) {\n      console.error('[Search Handler] Failed to generate embedding for the search query.');\n      return new Response('Failed to process search query (embedding generation failed)', { status: 500 });\n    }\n    console.log(`[Search Handler] Query embedding generated. Dimensions: ${queryEmbedding.length}`);\n  } catch (error) {\n    console.error('[Search Handler] Error generating query embedding:', error);\n    return new Response('Error processing search query', { status: 500 });\n  }\n\n  // 2. Query Vectorize index\n  let vectorMatches: any[]; // From VectorizeMatches.matches\n  try {\n    console.log(`[Search Handler] Querying Vectorize index with topK: ${topK}`);\n    const results = await env.VECTORIZE.query(queryEmbedding, { topK, returnValues: false }); // Don't need values back here\n    vectorMatches = results.matches;\n    console.log(`[Search Handler] Vectorize returned ${vectorMatches.length} matches.`);\n  } catch (error) {\n    console.error('[Search Handler] Error querying Vectorize index:', error);\n    return new Response('Error searching content', { status: 500 });\n  }\n\n  if (!vectorMatches || vectorMatches.length === 0) {\n    return new Response(JSON.stringify({ message: 'No results found.', results: [] }), {\n      status: 200,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  }\n\n  // 3. Extract IDs and scores from Vectorize results\n  const resultIds = vectorMatches.map(match => match.id);\n  const scoresMap = new Map(vectorMatches.map(match => [match.id, match.score]));\n\n  console.log(`[Search Handler] Fetching details from D1 for ${resultIds.length} IDs.`);\n\n  // 4. Fetch corresponding full log entries from D1\n  // Constructing the IN clause for the SQL query\n  // D1 prepare statements don't directly support arrays for IN clauses in a simple way other than binding each separately or creating placeholders.\n  // For a manageable number of IDs (like topK=10-20), creating placeholders is feasible.\n  const placeholders = resultIds.map(() => '?').join(',');\n  const sql = `\n    SELECT id, url, title, startTimestamp, endTimestamp, timeSpentSeconds, maxScrollPercent, tagsJson, summaryR2Key, processedAt \n    FROM logs \n    WHERE id IN (${placeholders})\n  `;\n  \n  let d1Results: SearchResultItem[];\n  try {\n    const stmt = env.ACTIVITY_LOG_DB.prepare(sql).bind(...resultIds);\n    const { results } = await stmt.all<SearchResultItem>(); // Make sure this matches the expected row type\n    d1Results = results || [];\n    console.log(`[Search Handler] D1 returned ${d1Results.length} full entries.`);\n  } catch (error) {\n    console.error('[Search Handler] Error fetching from D1:', error);\n    return new Response('Error retrieving search result details', { status: 500 });\n  }\n\n  // 5. Attempt to fetch summaries from R2 (optional, could be slow for many results)\n  //    For simplicity in this step, we'll rely on the client to fetch summaries if needed,\n  //    or assume the D1 record might eventually store a short summary directly if performance becomes an issue.\n  //    However, for a richer experience, we can fetch them here.\n\n  const searchResultsWithSummaries: SearchResultItem[] = [];\n  for (const item of d1Results) {\n      let summaryText: string | undefined = undefined;\n      if (item.summaryR2Key) { \n          try {\n              const r2Object = await env.ACTIVITY_SUMMARIES_BUCKET.get(item.summaryR2Key);\n              if (r2Object) {\n                  summaryText = await r2Object.text();\n              }\n          } catch (r2Error) {\n              console.warn(`[Search Handler] Failed to fetch summary from R2 for key ${item.summaryR2Key}:`, r2Error);\n          }\n      }\n      searchResultsWithSummaries.push({\n          ...item,\n          summary: summaryText,\n          score: scoresMap.get(item.id.toString()) // Ensure ID is string for map lookup if it isn't already\n      });\n  }\n  \n  // Preserve the order from Vectorize (most similar first)\n  searchResultsWithSummaries.sort((a, b) => (scoresMap.get(b.id.toString()) || 0) - (scoresMap.get(a.id.toString()) || 0));\n\n\n  console.log(`[Search Handler] Returning ${searchResultsWithSummaries.length} results.`);\n  return new Response(JSON.stringify({ results: searchResultsWithSummaries }), {\n    status: 200,\n    headers: { 'Content-Type': 'application/json' },\n  });\n}\n", "import { Env, Vector } from './types';\nimport { generateEmbedding } from './ai-processor';\n\ninterface BackfillResult {\n  totalLogsFetched: number;\n  summariesFound: number;\n  embeddingsGenerated: number;\n  vectorsUpserted: number;\n  errors: string[];\n}\n\n// Define a type for the rows we expect from D1 for backfilling\ninterface D1LogRecord {\n  id: string;\n  summaryR2Key: string | null;\n  // Add other fields you might want to log or inspect, but these are key for backfill\n  title: string | null;\n  url: string;\n}\n\nexport async function backfillHandler(_request: Request, env: Env): Promise<Response> {\n  console.log('[Backfill] Starting embedding backfill process...');\n  const results: BackfillResult = {\n    totalLogsFetched: 0,\n    summariesFound: 0,\n    embeddingsGenerated: 0,\n    vectorsUpserted: 0,\n    errors: [],\n  };\n\n  try {\n    // 1. Fetch all log entries from D1 that have a summaryR2Key\n    //    and potentially haven't been vectorized yet (though upsert is idempotent)\n    //    For simplicity, fetching all with summaryR2Key for now.\n    //    Adjust with a WHERE clause if you add a 'vectorized_at' field later.\n    const { results: logRecords, success: d1Success, error: d1Error } = await env.ACTIVITY_LOG_DB\n      .prepare('SELECT id, summaryR2Key, title, url FROM logs WHERE summaryR2Key IS NOT NULL')\n      .all<D1LogRecord>();\n\n    if (!d1Success) {\n      console.error('[Backfill] Failed to fetch logs from D1:', d1Error);\n      results.errors.push(`D1 query failed: ${d1Error}`);\n      return new Response(JSON.stringify(results), { status: 500, headers: { 'Content-Type': 'application/json' } });\n    }\n\n    if (!logRecords || logRecords.length === 0) {\n      results.errors.push('No log records with summaryR2Key found in D1 to process.');\n      console.log('[Backfill] No suitable log records found.');\n      return new Response(JSON.stringify(results), { status: 200, headers: { 'Content-Type': 'application/json' } });\n    }\n\n    results.totalLogsFetched = logRecords.length;\n    console.log(`[Backfill] Fetched ${results.totalLogsFetched} log records from D1.`);\n\n    const vectorsToUpsert: Vector[] = [];\n\n    // 2. For each log entry...\n    for (const record of logRecords) {\n      if (!record.summaryR2Key) {\n        // This shouldn't happen due to WHERE clause, but good to check\n        console.warn(`[Backfill] Skipping record ${record.id} as it has no summaryR2Key.`);\n        continue;\n      }\n\n      try {\n        // 2a. Fetch summary text from R2\n        const summaryObject = await env.ACTIVITY_SUMMARIES_BUCKET.get(record.summaryR2Key);\n        if (!summaryObject) {\n          const errMsg = `Summary not found in R2 for key: ${record.summaryR2Key} (log ID: ${record.id})`;\n          console.warn(`[Backfill] ${errMsg}`);\n          results.errors.push(errMsg);\n          continue;\n        }\n        const summaryText = await summaryObject.text();\n        results.summariesFound++;\n\n        // 2b. Generate embedding\n        const embeddingValues = await generateEmbedding(env.AI, summaryText);\n        if (!embeddingValues) {\n          const errMsg = `Failed to generate embedding for summary of log ID: ${record.id}`;\n          console.warn(`[Backfill] ${errMsg}`);\n          results.errors.push(errMsg);\n          continue;\n        }\n        results.embeddingsGenerated++;\n\n        // 2c. Prepare vector for upsert\n        vectorsToUpsert.push({\n          id: record.id, // Use D1 log ID as vector ID\n          values: embeddingValues,\n          // Optionally, include metadata if your Vectorize index is configured for it\n          // metadata: { title: record.title, url: record.url }\n        });\n\n      } catch (e: any) {\n        const errMsg = `Error processing record ${record.id}: ${e.message}`;\n        console.error(`[Backfill] ${errMsg}`, e);\n        results.errors.push(errMsg);\n      }\n    } // end for loop\n\n    // 3. Upsert vectors in batches (Vectorize supports up to 1000 vectors or 2MB per request)\n    // For simplicity, we'll do it in chunks of 100 here.\n    const batchSize = 100;\n    for (let i = 0; i < vectorsToUpsert.length; i += batchSize) {\n      const batch = vectorsToUpsert.slice(i, i + batchSize);\n      if (batch.length > 0) {\n        try {\n          console.log(`[Backfill] Upserting batch of ${batch.length} vectors to Vectorize... (Batch ${i / batchSize + 1})`);\n          const upsertResponse = await env.VECTORIZE.upsert(batch);\n          console.log('[Backfill] Vectorize upsert response:', upsertResponse);\n          results.vectorsUpserted += batch.length; // Assuming all in batch were processed if no error\n        } catch (e: any) {\n          const errMsg = `Error upserting batch to Vectorize: ${e.message}`;\n          console.error(`[Backfill] ${errMsg}`, e);\n          results.errors.push(errMsg);\n          // Potentially stop or skip to next batch depending on error type\n        }\n      }\n    }\n\n    console.log('[Backfill] Backfill process completed.');\n    return new Response(JSON.stringify(results), { status: 200, headers: { 'Content-Type': 'application/json' } });\n\n  } catch (error: any) {\n    console.error('[Backfill] Unhandled error during backfill process:', error);\n    results.errors.push(`Unhandled error: ${error.message}`);\n    return new Response(JSON.stringify(results), { status: 500, headers: { 'Content-Type': 'application/json' } });\n  }\n}\n", "// Configuration for the Activity Log Worker\n\nexport const config = {\n  cors: {\n    // Add your allowed origins here\n    // Chrome extensions use chrome-extension://EXTENSION_ID format\n    allowedOrigins: [\n      // Development origins\n      'http://localhost:8080',\n      'http://localhost:8787',\n      'http://localhost:3000',\n      'http://localhost:5173',\n      'http://127.0.0.1:8080',\n      'http://127.0.0.1:3000',\n      \n      // Production origins - UPDATE THESE WITH YOUR ACTUAL DOMAINS\n      // 'chrome-extension://YOUR_EXTENSION_ID',\n      // 'https://your-ui-domain.netlify.app',\n      // 'https://your-ui-domain.vercel.app', \n      // 'https://your-ui-domain.pages.dev',\n      // 'https://your-custom-domain.com'\n    ],\n    \n    // Allow requests with no origin (extensions, direct API calls)\n    allowNoOrigin: true,\n    \n    // Allow credentials in CORS requests\n    allowCredentials: true\n  },\n  \n  // Rate limiting configuration (for future implementation)\n  rateLimit: {\n    requestsPerMinute: 60,\n    requestsPerHour: 1000\n  },\n  \n  // Content size limits\n  limits: {\n    maxContentSize: 1024 * 1024, // 1MB\n    maxSummaryLength: 2000,\n    maxTags: 10\n  }\n};", "import { Router } from 'itty-router';\nimport { authHandler } from './auth-handler';\nimport { logHandler } from './log-handler';\nimport { getLogsHandler } from './get-logs-handler'; // Placeholder\nimport { getSummaryHandler } from './get-summary-handler'; // Placeholder\nimport { getContentHandler } from './get-content-handler';\nimport { searchHandler } from './search-handler'; // Import the new search handler\nimport { backfillHandler } from './backfill-handler'; // Import the backfill handler\nimport { Env } from './types';\nimport { config } from './config';\n\n// Create a new Router\nconst router = Router();\n\n// Helper function to add CORS headers\nfunction addCorsHeaders(response: Response, request: Request): Response {\n  const origin = request.headers.get('Origin');\n  \n  // Check if the origin is allowed\n  if (origin && config.cors.allowedOrigins.includes(origin)) {\n    response.headers.set('Access-Control-Allow-Origin', origin);\n  } else if (!origin && config.cors.allowNoOrigin) {\n    // Allow requests with no origin (e.g., from extensions or direct API calls)\n    response.headers.set('Access-Control-Allow-Origin', '*');\n  }\n  \n  response.headers.set('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');\n  response.headers.set('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Auth-Token');\n  \n  if (config.cors.allowCredentials) {\n    response.headers.set('Access-Control-Allow-Credentials', 'true');\n  }\n  \n  return response;\n}\n\n// Handle CORS preflight requests\nrouter.options('*', (request) => {\n  return addCorsHeaders(new Response(null, { status: 204 }), request);\n});\n\n/*\n * GET /ping: Simple route for testing connection and auth\n */\nrouter.get('/ping', authHandler, () => new Response('OK', { status: 200 }));\n\n/*\n * POST /log: Receives activity data from the extension,\n * processes it (AI summary/tags), stores summary in R2,\n * and stores metadata in D1.\n * Authentication is handled by authHandler.\n */\nrouter.post('/log', authHandler, logHandler); // Use the new logHandler\n\n// --- NEW API Endpoints for UI ---\n// Get recent log entries\nrouter.get('/logs', getLogsHandler);\n\n// Semantic search endpoint\nrouter.post('/search', authHandler, searchHandler);\n\n// Get summary for a specific log entry\nrouter.get('/logs/:id/summary', getSummaryHandler);\n\n// GET /log-content/:id - Fetch full text content for a specific log entry\nrouter.get('/log-content/:id', getContentHandler);\n\n// --- End NEW API Endpoints ---\n\n// --- Admin Endpoints ---\nrouter.get('/admin/backfill-embeddings', authHandler, backfillHandler);\n\n// Catch-all for 404s\nrouter.all('*', () => new Response('Not Found', { status: 404 }));\n\nexport default {\n  async fetch(request: Request, env: Env, _ctx: ExecutionContext): Promise<Response> {\n    try {\n      const response = await router.handle(request, env);\n      // Add CORS headers to actual responses\n      return addCorsHeaders(response, request);\n    } catch (error) {\n      console.error('Unhandled error:', error);\n      const errorResponse = new Response('Internal Server Error', { status: 500 });\n      return addCorsHeaders(errorResponse, request);\n    }\n  },\n};\n"],
  "mappings": ";;;;AAAA,SAAS,EAAE,EAAC,MAAK,IAAE,IAAG,QAAO,IAAE,CAAC,EAAC,IAAE,CAAC,GAAE;AAAC,SAAM,EAAC,WAAU,IAAI,MAAM,CAAC,GAAE,EAAC,KAAI,wBAACA,IAAE,GAAE,MAAI,CAACA,OAAK,MAAI,EAAE,KAAK,CAAC,EAAE,YAAY,GAAE,OAAO,KAAK,IAAEA,IAAG,QAAQ,YAAW,SAAS,EAAE,QAAQ,qBAAoB,EAAE,EAAE,QAAQ,qBAAoB,oBAAoB,EAAE,QAAQ,eAAc,KAAK,EAAE,QAAQ,yBAAwB,wBAAwB,CAAC,KAAK,GAAE,CAAC,CAAC,KAAG,GAA9Q,OAA+Q,CAAC,GAAE,QAAO,GAAE,MAAM,OAAOA,OAAK,GAAE;AAAC,QAAI,GAAE,GAAEC,KAAE,IAAI,IAAID,GAAE,GAAG;AAAE,IAAAA,GAAE,QAAM,OAAO,YAAYC,GAAE,YAAY;AAAE,aAAO,CAAC,GAAE,GAAE,CAAC,KAAI,EAAE,MAAI,MAAID,GAAE,UAAQ,UAAQ,OAAK,IAAEC,GAAE,SAAS,MAAM,CAAC,IAAG;AAAC,MAAAD,GAAE,SAAO,EAAE;AAAO,eAAQ,KAAK,EAAE,KAAG,YAAU,IAAE,MAAM,EAAEA,GAAE,SAAOA,IAAE,GAAG,CAAC,GAAG,QAAO;AAAA,IAAC;AAAA,EAAC,EAAC;AAAC;AAAplB;;;ACAT,eAAsB,YAAY,SAAkB,KAAU;AAC5D,UAAQ,IAAI,4BAA4B,OAAO,KAAK,OAAO,CAAC,CAAC,CAAC;AAC9D,QAAM,QAAQ,QAAQ,QAAQ,IAAI,cAAc;AAChD,QAAM,gBAAgB,KAAK;AAC3B,UAAQ,IAAI,kCAAkC,KAAK;AACnD,UAAQ,IAAI,kCAAkC,aAAa;AAC3D,QAAM,QAAQ,UAAU;AACxB,UAAQ,IAAI,4BAA4B,KAAK;AAC7C,MAAI,CAAC,OAAO;AACV,YAAQ,IAAI,4CAA4C;AACxD,WAAO,IAAI,SAAS,gBAAgB,EAAE,QAAQ,IAAI,CAAC;AAAA,EACrD;AACA,UAAQ,IAAI,2BAA2B;AAEvC,SAAO;AACT;AAfsB;;;ACUtB,eAAsB,kBAAkB,IAAS,aAA4E;AAC3H,MAAI,CAAC,eAAe,YAAY,KAAK,EAAE,WAAW,GAAG;AACnD,YAAQ,IAAI,4CAA4C;AACxD,WAAO,EAAE,SAAS,IAAI,UAAU,KAAK;AAAA,EACvC;AAGA,QAAM,kBAAkB;AACxB,QAAM,gBAAgB,YAAY,SAAS,kBACvC,YAAY,MAAM,GAAG,eAAe,IACpC;AAEJ,QAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYf,aAAa;AAAA;AAAA;AAAA;AAKb,MAAI;AACF,YAAQ,IAAI,iDAAiD;AAK7D,UAAM,cAAc,MAAM,GAAG,IAAI,2CAA2C,EAAE,OAAO,CAAC;AAEtF,YAAQ,IAAI,sCAAsC;AAGlD,QAAI,iBAAoC;AACxC,QAAI,eAAe,OAAO,YAAY,aAAa,UAAU;AAC3D,UAAI;AACF,yBAAiB,KAAK,MAAM,YAAY,SAAS,KAAK,CAAC;AACvD,gBAAQ,IAAI,sDAAsD;AAAA,MACpE,SAAS,YAAY;AACnB,gBAAQ,MAAM,yDAAyD,UAAU;AACjF,gBAAQ,MAAM,0CAA0C,YAAY,QAAQ;AAAA,MAC9E;AAAA,IACF,OAAO;AACL,cAAQ,MAAM,mEAAmE,WAAW;AAAA,IAC9F;AAGA,QAAI,kBAAkB,OAAO,eAAe,YAAY,YAAY,MAAM,QAAQ,eAAe,IAAI,GAAG;AAEtG,YAAM,YAAY,eAAe,KAAK,OAAO,CAAC,QAAa,OAAO,QAAQ,QAAQ;AAClF,aAAO;AAAA,QACL,SAAS,eAAe,QAAQ,KAAK;AAAA,QACrC,UAAU,KAAK,UAAU,SAAS;AAAA;AAAA,MACpC;AAAA,IACF,OAAO;AACL,cAAQ,MAAM,8EAA8E,cAAc;AAE1G,aAAO,EAAE,SAAS,cAAc,MAAM,GAAG,GAAG,IAAI,8BAA8B,UAAU,KAAK;AAAA,IAC/F;AAAA,EAEF,SAAS,OAAO;AACd,YAAQ,MAAM,4CAA4C,KAAK;AAE/D,WAAO,EAAE,SAAS,cAAc,MAAM,GAAG,GAAG,IAAI,6BAA6B,UAAU,KAAK;AAAA,EAC9F;AACF;AAxEsB;AA6EtB,eAAsB,kBAAkB,IAAS,WAA6C;AAC5F,MAAI,CAAC,aAAa,UAAU,KAAK,EAAE,WAAW,GAAG;AAC/C,YAAQ,IAAI,uEAAuE;AACnF,WAAO;AAAA,EACT;AAIA,QAAM,4BAA4B;AAClC,QAAM,OAAO,UAAU,SAAS,4BAC5B,UAAU,MAAM,GAAG,yBAAyB,IAC5C;AAEJ,MAAI;AACF,YAAQ,IAAI,8EAA8E,UAAU,MAAM,uBAAuB,KAAK,MAAM,IAAI;AAChJ,UAAM,QAAQ;AACd,UAAM,WAAW,MAAM,GAAG,IAAI,OAAO,EAAE,KAAK,CAAC;AAG7C,QAAI,YAAY,SAAS,QAAQ,MAAM,QAAQ,SAAS,IAAI,KAAK,SAAS,KAAK,SAAS,KACpF,MAAM,QAAQ,SAAS,KAAK,CAAC,CAAC,KAAK,SAAS,KAAK,CAAC,EAAE,SAAS,GAAG;AAClE,cAAQ,IAAI,4EAA4E,SAAS,KAAK,CAAC,EAAE,MAAM,EAAE;AACjH,aAAO,SAAS,KAAK,CAAC;AAAA,IACxB,OAAO;AACL,cAAQ,MAAM,8FAA8F;AAE5G,UAAI;AACF,gBAAQ,MAAM,+CAA+C,KAAK,UAAU,QAAQ,EAAE,MAAM,GAAG,GAAG,CAAC;AAAA,MACrG,SAASE,IAAG;AACV,gBAAQ,MAAM,iEAAiE,QAAQ;AAAA,MACzF;AACA,aAAO;AAAA,IACT;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,sEAAsE,KAAK;AACzF,WAAO;AAAA,EACT;AACF;AArCsB;;;ACnFtB,IAAM,kBAAN,MAAsB;AAAA,EAAtB;AACI,cAAa;AACb,cAAa;AAAA;AAAA,EANjB,OAIsB;AAAA;AAAA;AAAA;AAAA,EAKV,QAAQ,GAAW,IAAY,IAAsC;AACzE,QAAI,SAAS,EAAE;AACf,QAAI,GAAW,GAAW;AAE1B,QAAI,IAAI,IAAI,aAAa,SAAS;AAClC,SAAK;AAEL,QAAI,SAAS;AACb,WAAO,SAAS,IAAI;AAChB,WAAK,EAAE,WAAW,SAAS,CAAC;AAC5B,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AACjC,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AACjC,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAEjC,WAAK,EAAE,WAAW,SAAS,CAAC;AAC5B,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AACjC,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AACjC,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAEjC,WAAK,EAAE,WAAW,SAAS,CAAC;AAC5B,WAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AACjC,WAAK,EAAE,WAAW,SAAS,EAAE,KAAK;AAClC,WAAK,EAAE,WAAW,SAAS,EAAE,KAAK;AAElC,YAAM,QAAQ,KAAK,IAAI,GAAG,GAAG,CAAC;AAC9B,UAAI,MAAM;AACV,UAAI,MAAM;AACV,UAAI,MAAM;AAEV,gBAAU;AACV,gBAAU;AAAA,IACd;AAEA,YAAQ,QAAQ;AAAA;AAAA,MACZ,KAAK;AAAI,aAAK,EAAE,WAAW,SAAS,EAAE,KAAK;AAAA;AAAA,MAC3C,KAAK;AAAI,aAAK,EAAE,WAAW,SAAS,EAAE,KAAK;AAAA;AAAA,MAC3C,KAAK;AAAI,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MAC1C,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC;AAAA;AAAA,MACpC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC;AAAA;AAAA,MACpC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC,KAAK;AAAA;AAAA,MACzC,KAAK;AAAG,aAAK,EAAE,WAAW,SAAS,CAAC;AAChC;AAAA,MACJ,KAAK;AAAG,eAAO,EAAE,GAAG,MAAM,GAAG,GAAG,MAAM,EAAE;AAAA,IAC5C;AAEA,UAAM,aAAa,KAAK,SAAS,GAAG,GAAG,CAAC;AACxC,QAAI,WAAW;AACf,QAAI,WAAW;AACf,QAAI,WAAW;AAEf,WAAO,EAAE,GAAG,MAAM,GAAG,GAAG,MAAM,EAAE;AAAA,EACpC;AAAA;AAAA,EAGQ,IAAI,GAAW,GAAW,GAAgD;AAC9E,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,CAAC;AAAG,SAAK;AAClC,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,CAAC;AAAG,SAAK;AAClC,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,CAAC;AAAG,SAAK;AAClC,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAAG,SAAK;AACnC,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAAG,SAAK;AACnC,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,CAAC;AAAG,SAAK;AAClC,WAAO,EAAE,GAAM,GAAM,EAAK;AAAA,EAC9B;AAAA;AAAA,EAGQ,SAAS,GAAW,GAAW,GAAgD;AACnF,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,CAAC;AAC1B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,SAAK;AAAG,SAAK,KAAK,IAAI,GAAG,EAAE;AAC3B,WAAO,EAAE,GAAM,GAAM,EAAK;AAAA,EAC9B;AAAA;AAAA,EAGQ,IAAI,GAAW,GAAmB;AACtC,WAAU,KAAO,IAAQ,MAAQ,KAAM;AAAA,EAC3C;AAAA;AAAA,EAGO,OAAO,KAAqB;AAC/B,UAAM,IAAI,KAAK,QAAQ,KAAK,KAAK,IAAI,KAAK,EAAE;AAC5C,WAAO,EAAE;AAAA,EACb;AACJ;AAQO,IAAM,UAAN,MAAc;AAAA,EA5GrB,OA4GqB;AAAA;AAAA;AAAA,EAKjB,YAAY,SAA0B;AAClC,SAAK,YAAY,SAAS,aAAa;AACvC,SAAK,cAAc,SAAS,eAAe;AAC3C,SAAK,UAAU,IAAI,gBAAgB;AAAA,EACvC;AAAA;AAAA,EAGQ,SAAS,UAA4B;AACzC,UAAM,OAAO,SAAS;AACtB,QAAI,QAAQ,KAAK,WAAW;AACxB,aAAO,CAAC,QAAQ;AAAA,IACpB;AACA,UAAM,WAAqB,CAAC;AAC5B,aAAS,IAAI,GAAG,IAAI,MAAM,IAAI,IAAI,KAAK,WAAW;AAC9C,eAAS,KAAK,IAAI,KAAK,YAAY,OAAO,SAAS,MAAM,GAAG,IAAI,KAAK,SAAS,IAAI,SAAS,MAAM,CAAC,CAAC;AAAA,IACvG;AACA,WAAO;AAAA,EACX;AAAA;AAAA,EAGQ,gBAAgB,UAA4B;AAChD,QAAI,SAAS,WAAW,EAAG,QAAO;AAClC,QAAI,SAAS,WAAW,EAAG,QAAO,SAAS,CAAC;AAG5C,aAAS,KAAK,CAAC,GAAG,MAAM,IAAI,CAAC;AAC7B,QAAI,SAAS,SAAS,KAAK,aAAa;AACpC,iBAAW,SAAS,MAAM,GAAG,KAAK,WAAW;AAAA,IACjD;AAEA,QAAI,UAAU;AACd,aAAS,MAAM,GAAG,MAAM,IAAI,OAAO;AAC/B,UAAI,SAAS;AACb,YAAM,OAAO,KAAK;AAClB,iBAAW,WAAW,UAAU;AAE5B,mBAAW,UAAU,UAAU,IAAI,IAAI;AAAA,MAC3C;AACA,UAAI,SAAS,GAAG;AACZ,mBAAW;AAAA,MACf;AAAA,IACJ;AACA,WAAO,YAAY;AAAA,EACvB;AAAA;AAAA,EAGO,KAAK,OAAuB;AAC/B,UAAM,SAAS,KAAK,SAAS,KAAK;AAClC,UAAM,WAAqB,OAAO,IAAI,WAAS,KAAK,QAAQ,OAAO,KAAK,CAAC;AACzE,UAAM,eAAe,KAAK,gBAAgB,QAAQ;AAClD,WAAO;AAAA,EACX;AACJ;AAGO,IAAM,aAAN,MAAiB;AAAA,EAxKxB,OAwKwB;AAAA;AAAA;AAAA;AAAA,EAEpB,OAAO,gBAAgB,GAAW,GAAmB;AAIjD,QAAI;AACA,YAAM,KAAK,SAAS,GAAG,EAAE;AACzB,YAAM,KAAK,SAAS,GAAG,EAAE;AAEzB,UAAI,MAAM,EAAE,KAAK,MAAM,EAAE,GAAG;AACxB,gBAAQ,MAAM,4CAA4C,GAAG,CAAC;AAC9D,eAAO;AAAA,MACX;AAEA,UAAI,YAAY,KAAK;AACrB,UAAI,WAAW;AACf,aAAO,YAAY,GAAG;AAClB;AACA,qBAAc,YAAY;AAAA,MAC9B;AACA,aAAO;AAAA,IACX,SAASC,IAAG;AACP,cAAQ,MAAM,uCAAuCA,EAAC;AACtD,aAAO;AAAA,IACZ;AAAA,EACJ;AAAA;AAAA,EAGA,OAAO,WAAW,GAAW,GAAmB;AAC3C,QAAI;AACD,YAAM,KAAK,SAAS,GAAG,EAAE;AACzB,YAAM,KAAK,SAAS,GAAG,EAAE;AACzB,UAAI,MAAM,EAAE,KAAK,MAAM,EAAE,EAAG,QAAO;AAEnC,YAAM,eAAe,KAAK;AAC1B,YAAM,QAAQ,KAAK;AAEnB,YAAM,qBAAqB,KAAK,cAAc,YAAY;AAC1D,YAAM,cAAc,KAAK,cAAc,KAAK;AAE5C,aAAO,gBAAgB,IAAI,IAAI,qBAAqB;AAAA,IACvD,SAAQA,IAAG;AACR,aAAO;AAAA,IACV;AAAA,EACL;AAAA;AAAA,EAGA,OAAO,cAAc,GAAmB;AACpC,QAAI,QAAQ;AACZ,WAAO,IAAI,GAAG;AACV,WAAM,IAAI;AACV;AAAA,IACJ;AACA,WAAO;AAAA,EACX;AACJ;;;ACzNA,eAAe,YAAY,QAAsC;AAC/D,QAAM,YAAY,MAAM,KAAK,IAAI,WAAW,MAAM,CAAC;AACnD,QAAM,UAAU,UAAU,IAAI,OAAK,EAAE,SAAS,EAAE,EAAE,SAAS,GAAG,GAAG,CAAC,EAAE,KAAK,EAAE;AAC3E,SAAO;AACT;AAJe;AAOf,eAAe,cAAc,MAA+B;AAC1D,QAAM,UAAU,IAAI,YAAY;AAChC,QAAM,OAAO,QAAQ,OAAO,IAAI;AAChC,QAAM,aAAa,MAAM,OAAO,OAAO,OAAO,WAAW,IAAI;AAC7D,SAAO,YAAY,UAAU;AAC/B;AALe;AAQf,IAAM,oBAAoB;AAE1B,eAAsB,WAAW,SAAkB,KAAU;AAC3D,MAAI,UAAyE;AAE7E,MAAI;AACF,UAAM,eAAmG,MAAM,QAAQ,KAAK;AAC5H,YAAQ,IAAI,gCAAgC,KAAK,UAAU,YAAY,EAAE,MAAM,GAAG,GAAG,IAAI,KAAK;AAG9F,UAAM,gBAAgB,CAAC;AACvB,QAAI,CAAC,aAAa,IAAK,eAAc,KAAK,KAAK;AAC/C,QAAI,CAAC,aAAa,eAAgB,eAAc,KAAK,gBAAgB;AACrE,QAAI,CAAC,aAAa,YAAa,eAAc,KAAK,aAAa;AAE/D,QAAI,cAAc,SAAS,GAAG;AAC5B,cAAQ,MAAM,wDAAwD,aAAa;AACnF,cAAQ,MAAM,kCAAkC,OAAO,KAAK,YAAY,CAAC;AACzE,aAAO,IAAI,SAAS,yCAAyC,cAAc,KAAK,IAAI,CAAC,IAAI,EAAE,QAAQ,IAAI,CAAC;AAAA,IAC1G;AAGA,cAAU;AAAA,MACR,GAAG;AAAA,MACH,IAAI,aAAa,MAAM,OAAO,WAAW;AAAA;AAAA,MACzC,aAAa,KAAK,IAAI;AAAA,IACxB;AAEA,YAAQ,IAAI,oCAAoC,QAAQ,EAAE,EAAE;AAG5D,UAAM,cAAc,MAAM,cAAc,QAAQ,WAAW;AAC3D,YAAQ,IAAI,0CAA0C,WAAW,gBAAgB,QAAQ,EAAE,EAAE;AAE7F,UAAM,YAAY,IAAI,gBAAgB;AAAA,MACpC;AAAA,IACF,EAAE,KAAK,WAAW;AAElB,UAAM,cAAc,MAAM,UAAU,MAAM;AAE1C,QAAI,aAAa;AACf,cAAQ,IAAI,gEAAgE,YAAY,EAAE,0CAA0C,QAAQ,EAAE,GAAG;AAEjJ,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,0CAA0C,eAAe,YAAY,GAAG,CAAC,GAAG;AAAA,QACxH,QAAQ;AAAA;AAAA,QACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAChD,CAAC;AAAA,IACH;AAIA,UAAM,YAAY,IAAI,QAAQ;AAC9B,UAAM,gBAAgB,UAAU,KAAK,QAAQ,WAAW;AACxD,UAAM,mBAAmB,cAAc,SAAS,EAAE,EAAE,SAAS,GAAG,GAAG;AAEnE,UAAM,kBAAkB,IAAI,gBAAgB;AAAA,MAC1C;AAAA,IACF;AACA,UAAM,cAAc,MAAM,gBAAgB,KAAK,QAAQ,GAAG,EAAE,MAAqD;AAEjH,QAAI,aAAa,gBAAgB;AAC/B,UAAI;AACF,cAAM,wBAAwB,YAAY;AAC1C,cAAM,WAAW,WAAW,gBAAgB,kBAAkB,qBAAqB;AAEnF,gBAAQ,IAAI,sBAAsB,QAAQ,GAAG,kBAAkB,gBAAgB,mBAAmB,YAAY,cAAc,eAAe,QAAQ,EAAE;AAErJ,YAAI,YAAY,mBAAmB;AACjC,kBAAQ,IAAI,oDAAoD,QAAQ,GAAG,eAAe,QAAQ,qBAAqB;AAEvH,iBAAO,IAAI,SAAS,8CAA8C,EAAE,QAAQ,IAAI,CAAC;AAAA,QAEnF;AAAA,MACF,SAAS,cAAc;AACrB,gBAAQ,MAAM,yDAAyD,QAAQ,GAAG,KAAK,YAAY;AAAA,MAErG;AAAA,IACF;AAIA,QAAI,WAAW,MAAM,kBAAkB,IAAI,IAAI,QAAQ,WAAW;AAClE,QAAI,CAAC,UAAU;AAEb,cAAQ,KAAK,kDAAkD,QAAQ,EAAE,mBAAmB;AAE5F,iBAAW,EAAE,SAAS,QAAQ,YAAY,MAAM,GAAG,GAAG,IAAI,8BAA8B,UAAU,KAAK;AAAA,IACzG;AACA,UAAM,EAAE,SAAS,SAAS,IAAI;AAG9B,UAAM,eAAe,GAAG,QAAQ,EAAE;AAClC,YAAQ,IAAI,iDAAiD,YAAY,EAAE;AAC3E,QAAI;AACF,YAAM,IAAI,0BAA0B,IAAI,cAAc,OAAO;AAC7D,cAAQ,IAAI,+DAA+D,QAAQ,EAAE,EAAE;AAAA,IACzF,SAAS,SAAS;AAChB,cAAQ,MAAM,2DAA2D,QAAQ,EAAE,KAAK,OAAO;AAAA,IAGjG;AAGA,UAAM,eAAe,GAAG,QAAQ,EAAE;AAClC,QAAI;AACF,YAAM,IAAI,0BAA0B,IAAI,cAAc,QAAQ,WAAW;AACzE,cAAQ,IAAI,+DAA+D,QAAQ,EAAE,EAAE;AAAA,IACzF,SAAS,KAAK;AACZ,cAAQ,MAAM,2DAA2D,QAAQ,EAAE,KAAK,GAAG;AAE3F,aAAO,IAAI,SAAS,gDAAgD,EAAE,QAAQ,IAAI,CAAC;AAAA,IACrF;AAGA,YAAQ,IAAI,oDAAoD,QAAQ,EAAE,EAAE;AAC5E,UAAM,OAAO,IAAI,gBAAgB;AAAA,MAC/B;AAAA;AAAA,IAEF;AAEA,QAAI;AACF,YAAM,WAAW,MAAM,KAAK;AAAA,QAC1B,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR,QAAQ,SAAS;AAAA;AAAA,QACjB,QAAQ;AAAA,QACR,QAAQ,gBAAgB;AAAA;AAAA,QACxB,QAAQ,oBAAoB;AAAA;AAAA,QAC5B,QAAQ,oBAAoB;AAAA;AAAA,QAC5B;AAAA,QACA;AAAA,QACA;AAAA,QACA,QAAQ;AAAA,QACR;AAAA,QACA;AAAA;AAAA,MACF,EAAE,IAAI;AAEN,UAAI,SAAS,SAAS;AACpB,gBAAQ,IAAI,gEAAgE,QAAQ,EAAE,EAAE;AAGxF,YAAI,WAAW,QAAQ,KAAK,MAAM,MAAM,CAAC,QAAQ,SAAS,wBAAwB,KAAK,CAAC,QAAQ,SAAS,uBAAuB,GAAG;AAC/H,cAAI;AACA,oBAAQ,IAAI,yEAAyE,QAAQ,EAAE,EAAE;AACjG,kBAAM,kBAAkB,MAAM,kBAAkB,IAAI,IAAI,OAAO;AAE/D,gBAAI,iBAAiB;AACjB,sBAAQ,IAAI,6DAA6D,QAAQ,EAAE,iBAAiB,gBAAgB,MAAM,EAAE;AAC5H,oBAAM,iBAAiB;AAAA,gBACnB,IAAI,QAAQ;AAAA;AAAA,gBACZ,QAAQ;AAAA;AAAA,cAEZ;AACA,oBAAM,IAAI,UAAU,OAAO,CAAC,cAAc,CAAC;AAC3C,sBAAQ,IAAI,sEAAsE,QAAQ,EAAE,wBAAwB;AAAA,YACxH,OAAO;AACH,sBAAQ,KAAK,4EAA4E,QAAQ,EAAE,8BAA8B;AAAA,YACrI;AAAA,UACJ,SAAS,gBAAgB;AACrB,oBAAQ,MAAM,+FAA+F,QAAQ,EAAE,KAAK,cAAc;AAAA,UAE9I;AAAA,QACJ,OAAO;AACH,kBAAQ,IAAI,4DAA4D,QAAQ,EAAE,+CAA+C;AAAA,QACrI;AAGA,eAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,+BAA+B,OAAO,QAAQ,GAAG,CAAC,GAAG;AAAA,UACjG,QAAQ;AAAA,UACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,QAChD,CAAC;AAAA,MACH,OAAO;AACL,gBAAQ,MAAM,8CAA8C,QAAQ,EAAE,IAAI,SAAS,KAAK;AAExF,eAAO,IAAI,SAAS,gCAAgC,EAAE,QAAQ,IAAI,CAAC;AAAA,MACrE;AAAA,IACF,SAAS,SAAS;AAChB,cAAQ,MAAM,+CAA+C,QAAQ,EAAE,IAAI,OAAO;AAClF,aAAO,IAAI,SAAS,kBAAkB,EAAE,QAAQ,IAAI,CAAC;AAAA,IACvD;AAAA,EAEF,SAAS,KAAU;AACjB,QAAI,eAAe,aAAa;AAC9B,cAAQ,MAAM,wCAAwC,GAAG;AACzD,aAAO,IAAI,SAAS,gBAAgB,EAAE,QAAQ,IAAI,CAAC;AAAA,IACrD;AACA,YAAQ,MAAM,kDAAkD,GAAG;AAEnE,UAAM,QAAQ,UAAU,QAAQ,KAAK;AACrC,YAAQ,MAAM,mDAAmD,KAAK,EAAE;AACxE,WAAO,IAAI,SAAS,yBAAyB,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC9D;AACF;AA9LsB;;;ACrBtB,eAAsB,eAAe,UAAmB,KAA6B;AACnF,UAAQ,IAAI,qCAAqC;AAEjD,MAAI;AACF,UAAM,OAAO,IAAI,gBAAgB;AAAA,MAC/B;AAAA;AAAA;AAAA;AAAA,IAIF;AAEA,UAAM,EAAE,QAAQ,IAAI,MAAM,KAAK,IAAI;AAEnC,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,MAAM,QAAQ,CAAC,GAAG;AAAA,MACrD,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,QAAQ;AAAA,IACV,CAAC;AAAA,EAEH,SAAS,OAAO;AACd,YAAQ,MAAM,2CAA2C,KAAK;AAC9D,WAAO,IAAI,SAAS,uBAAuB,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC5D;AACF;AAtBsB;;;ACCtB,eAAsB,kBAAkB,SAAkB,KAA6B;AACrF,QAAM,QAAQ,QAAQ,QAAQ;AAC9B,UAAQ,IAAI,sDAAsD,KAAK,EAAE;AAEzE,MAAI,CAAC,OAAO;AACV,WAAO,IAAI,SAAS,4BAA4B,EAAE,QAAQ,IAAI,CAAC;AAAA,EACjE;AAEA,MAAI;AACF,UAAM,aAAa,GAAG,KAAK;AAE3B,YAAQ,IAAI,gDAAgD,UAAU,oBAAoB,IAAI,yBAAyB,EAAE;AACzH,UAAM,gBAAgB,MAAM,IAAI,0BAA0B,IAAI,UAAU;AAExE,QAAI,kBAAkB,MAAM;AAC1B,cAAQ,KAAK,0DAA0D,UAAU,EAAE;AACnF,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,oBAAoB,CAAC,GAAG;AAAA,QAClE,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,QAC9C,QAAQ;AAAA,MACV,CAAC;AAAA,IACH;AAEA,YAAQ,IAAI,iEAAiE,UAAU,EAAE;AAGzF,UAAM,cAAc,MAAM,cAAc,KAAK;AAE7C,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,YAAY,CAAC,GAAG;AAAA,MAC5D,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,QAAQ;AAAA,IACV,CAAC;AAAA,EAEH,SAAS,OAAO;AACd,YAAQ,MAAM,2DAA2D,KAAK,KAAK,KAAK;AACxF,WAAO,IAAI,SAAS,0BAA0B,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC/D;AACF;AApCsB;;;ACFtB,eAAsB,kBAAkB,SAAkB,KAA6B;AACrF,QAAM,QAAS,QAAgB,QAAQ;AAEvC,MAAI,CAAC,OAAO;AACV,WAAO,IAAI,SAAS,mCAAmC,EAAE,QAAQ,IAAI,CAAC;AAAA,EACxE;AAEA,UAAQ,IAAI,sDAAsD,KAAK,EAAE;AAGzE,QAAM,aAAa,GAAG,KAAK;AAE3B,MAAI;AACF,YAAQ,IAAI,gDAAgD,UAAU,oBAAoB,IAAI,yBAAyB,EAAE;AACzH,UAAM,WAAW,MAAM,IAAI,0BAA0B,IAAI,UAAU;AAEnE,QAAI,aAAa,MAAM;AACrB,cAAQ,IAAI,oDAAoD,UAAU,EAAE;AAC5E,aAAO,IAAI,SAAS,+CAA+C,EAAE,QAAQ,IAAI,CAAC;AAAA,IACpF;AAEA,YAAQ,IAAI,iEAAiE,UAAU,EAAE;AAIzF,UAAM,UAAU,IAAI,QAAQ;AAAA,MAC1B,gBAAgB;AAAA;AAAA;AAAA,IAGlB,CAAC;AACD,WAAO,IAAI,SAAS,SAAS,MAAM,EAAE,SAAkB,QAAQ,IAAI,CAAC;AAAA,EAEtE,SAAS,KAAK;AACZ,YAAQ,MAAM,kEAAkE,UAAU,KAAK,GAAG;AAClG,WAAO,IAAI,SAAS,wDAAwD,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC7F;AACF;AApCsB;;;ACoBtB,eAAsB,cAAc,SAAkB,KAA6B;AACjF,MAAI,QAAQ,WAAW,QAAQ;AAC7B,WAAO,IAAI,SAAS,sBAAsB,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC3D;AAEA,MAAI;AACJ,MAAI;AACF,cAAU,MAAM,QAAQ,KAAK;AAAA,EAC/B,SAASC,IAAG;AACV,WAAO,IAAI,SAAS,wBAAwB,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC7D;AAEA,QAAM,EAAE,OAAO,OAAO,GAAG,IAAI;AAE7B,MAAI,CAAC,SAAS,OAAO,UAAU,YAAY,MAAM,KAAK,EAAE,WAAW,GAAG;AACpE,WAAO,IAAI,SAAS,oCAAoC,EAAE,QAAQ,IAAI,CAAC;AAAA,EACzE;AAEA,UAAQ,IAAI,4CAA4C,KAAK,YAAY,IAAI,EAAE;AAG/E,MAAI;AACJ,MAAI;AACF,YAAQ,IAAI,qDAAqD,KAAK,GAAG;AACzE,qBAAiB,MAAM,kBAAkB,IAAI,IAAI,KAAK;AACtD,QAAI,CAAC,gBAAgB;AACnB,cAAQ,MAAM,qEAAqE;AACnF,aAAO,IAAI,SAAS,gEAAgE,EAAE,QAAQ,IAAI,CAAC;AAAA,IACrG;AACA,YAAQ,IAAI,2DAA2D,eAAe,MAAM,EAAE;AAAA,EAChG,SAAS,OAAO;AACd,YAAQ,MAAM,sDAAsD,KAAK;AACzE,WAAO,IAAI,SAAS,iCAAiC,EAAE,QAAQ,IAAI,CAAC;AAAA,EACtE;AAGA,MAAI;AACJ,MAAI;AACF,YAAQ,IAAI,wDAAwD,IAAI,EAAE;AAC1E,UAAM,UAAU,MAAM,IAAI,UAAU,MAAM,gBAAgB,EAAE,MAAM,cAAc,MAAM,CAAC;AACvF,oBAAgB,QAAQ;AACxB,YAAQ,IAAI,uCAAuC,cAAc,MAAM,WAAW;AAAA,EACpF,SAAS,OAAO;AACd,YAAQ,MAAM,oDAAoD,KAAK;AACvE,WAAO,IAAI,SAAS,2BAA2B,EAAE,QAAQ,IAAI,CAAC;AAAA,EAChE;AAEA,MAAI,CAAC,iBAAiB,cAAc,WAAW,GAAG;AAChD,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,qBAAqB,SAAS,CAAC,EAAE,CAAC,GAAG;AAAA,MACjF,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,IAChD,CAAC;AAAA,EACH;AAGA,QAAM,YAAY,cAAc,IAAI,WAAS,MAAM,EAAE;AACrD,QAAM,YAAY,IAAI,IAAI,cAAc,IAAI,WAAS,CAAC,MAAM,IAAI,MAAM,KAAK,CAAC,CAAC;AAE7E,UAAQ,IAAI,iDAAiD,UAAU,MAAM,OAAO;AAMpF,QAAM,eAAe,UAAU,IAAI,MAAM,GAAG,EAAE,KAAK,GAAG;AACtD,QAAM,MAAM;AAAA;AAAA;AAAA,mBAGK,YAAY;AAAA;AAG7B,MAAI;AACJ,MAAI;AACF,UAAM,OAAO,IAAI,gBAAgB,QAAQ,GAAG,EAAE,KAAK,GAAG,SAAS;AAC/D,UAAM,EAAE,QAAQ,IAAI,MAAM,KAAK,IAAsB;AACrD,gBAAY,WAAW,CAAC;AACxB,YAAQ,IAAI,gCAAgC,UAAU,MAAM,gBAAgB;AAAA,EAC9E,SAAS,OAAO;AACd,YAAQ,MAAM,4CAA4C,KAAK;AAC/D,WAAO,IAAI,SAAS,0CAA0C,EAAE,QAAQ,IAAI,CAAC;AAAA,EAC/E;AAOA,QAAM,6BAAiD,CAAC;AACxD,aAAW,QAAQ,WAAW;AAC1B,QAAI,cAAkC;AACtC,QAAI,KAAK,cAAc;AACnB,UAAI;AACA,cAAM,WAAW,MAAM,IAAI,0BAA0B,IAAI,KAAK,YAAY;AAC1E,YAAI,UAAU;AACV,wBAAc,MAAM,SAAS,KAAK;AAAA,QACtC;AAAA,MACJ,SAAS,SAAS;AACd,gBAAQ,KAAK,4DAA4D,KAAK,YAAY,KAAK,OAAO;AAAA,MAC1G;AAAA,IACJ;AACA,+BAA2B,KAAK;AAAA,MAC5B,GAAG;AAAA,MACH,SAAS;AAAA,MACT,OAAO,UAAU,IAAI,KAAK,GAAG,SAAS,CAAC;AAAA;AAAA,IAC3C,CAAC;AAAA,EACL;AAGA,6BAA2B,KAAK,CAAC,GAAG,OAAO,UAAU,IAAI,EAAE,GAAG,SAAS,CAAC,KAAK,MAAM,UAAU,IAAI,EAAE,GAAG,SAAS,CAAC,KAAK,EAAE;AAGvH,UAAQ,IAAI,8BAA8B,2BAA2B,MAAM,WAAW;AACtF,SAAO,IAAI,SAAS,KAAK,UAAU,EAAE,SAAS,2BAA2B,CAAC,GAAG;AAAA,IAC3E,QAAQ;AAAA,IACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,EAChD,CAAC;AACH;AApHsB;;;ACFtB,eAAsB,gBAAgB,UAAmB,KAA6B;AACpF,UAAQ,IAAI,mDAAmD;AAC/D,QAAM,UAA0B;AAAA,IAC9B,kBAAkB;AAAA,IAClB,gBAAgB;AAAA,IAChB,qBAAqB;AAAA,IACrB,iBAAiB;AAAA,IACjB,QAAQ,CAAC;AAAA,EACX;AAEA,MAAI;AAKF,UAAM,EAAE,SAAS,YAAY,SAAS,WAAW,OAAO,QAAQ,IAAI,MAAM,IAAI,gBAC3E,QAAQ,8EAA8E,EACtF,IAAiB;AAEpB,QAAI,CAAC,WAAW;AACd,cAAQ,MAAM,4CAA4C,OAAO;AACjE,cAAQ,OAAO,KAAK,oBAAoB,OAAO,EAAE;AACjD,aAAO,IAAI,SAAS,KAAK,UAAU,OAAO,GAAG,EAAE,QAAQ,KAAK,SAAS,EAAE,gBAAgB,mBAAmB,EAAE,CAAC;AAAA,IAC/G;AAEA,QAAI,CAAC,cAAc,WAAW,WAAW,GAAG;AAC1C,cAAQ,OAAO,KAAK,0DAA0D;AAC9E,cAAQ,IAAI,2CAA2C;AACvD,aAAO,IAAI,SAAS,KAAK,UAAU,OAAO,GAAG,EAAE,QAAQ,KAAK,SAAS,EAAE,gBAAgB,mBAAmB,EAAE,CAAC;AAAA,IAC/G;AAEA,YAAQ,mBAAmB,WAAW;AACtC,YAAQ,IAAI,sBAAsB,QAAQ,gBAAgB,uBAAuB;AAEjF,UAAM,kBAA4B,CAAC;AAGnC,eAAW,UAAU,YAAY;AAC/B,UAAI,CAAC,OAAO,cAAc;AAExB,gBAAQ,KAAK,8BAA8B,OAAO,EAAE,6BAA6B;AACjF;AAAA,MACF;AAEA,UAAI;AAEF,cAAM,gBAAgB,MAAM,IAAI,0BAA0B,IAAI,OAAO,YAAY;AACjF,YAAI,CAAC,eAAe;AAClB,gBAAM,SAAS,oCAAoC,OAAO,YAAY,aAAa,OAAO,EAAE;AAC5F,kBAAQ,KAAK,cAAc,MAAM,EAAE;AACnC,kBAAQ,OAAO,KAAK,MAAM;AAC1B;AAAA,QACF;AACA,cAAM,cAAc,MAAM,cAAc,KAAK;AAC7C,gBAAQ;AAGR,cAAM,kBAAkB,MAAM,kBAAkB,IAAI,IAAI,WAAW;AACnE,YAAI,CAAC,iBAAiB;AACpB,gBAAM,SAAS,uDAAuD,OAAO,EAAE;AAC/E,kBAAQ,KAAK,cAAc,MAAM,EAAE;AACnC,kBAAQ,OAAO,KAAK,MAAM;AAC1B;AAAA,QACF;AACA,gBAAQ;AAGR,wBAAgB,KAAK;AAAA,UACnB,IAAI,OAAO;AAAA;AAAA,UACX,QAAQ;AAAA;AAAA;AAAA,QAGV,CAAC;AAAA,MAEH,SAASC,IAAQ;AACf,cAAM,SAAS,2BAA2B,OAAO,EAAE,KAAKA,GAAE,OAAO;AACjE,gBAAQ,MAAM,cAAc,MAAM,IAAIA,EAAC;AACvC,gBAAQ,OAAO,KAAK,MAAM;AAAA,MAC5B;AAAA,IACF;AAIA,UAAM,YAAY;AAClB,aAAS,IAAI,GAAG,IAAI,gBAAgB,QAAQ,KAAK,WAAW;AAC1D,YAAM,QAAQ,gBAAgB,MAAM,GAAG,IAAI,SAAS;AACpD,UAAI,MAAM,SAAS,GAAG;AACpB,YAAI;AACF,kBAAQ,IAAI,iCAAiC,MAAM,MAAM,mCAAmC,IAAI,YAAY,CAAC,GAAG;AAChH,gBAAM,iBAAiB,MAAM,IAAI,UAAU,OAAO,KAAK;AACvD,kBAAQ,IAAI,yCAAyC,cAAc;AACnE,kBAAQ,mBAAmB,MAAM;AAAA,QACnC,SAASA,IAAQ;AACf,gBAAM,SAAS,uCAAuCA,GAAE,OAAO;AAC/D,kBAAQ,MAAM,cAAc,MAAM,IAAIA,EAAC;AACvC,kBAAQ,OAAO,KAAK,MAAM;AAAA,QAE5B;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,IAAI,wCAAwC;AACpD,WAAO,IAAI,SAAS,KAAK,UAAU,OAAO,GAAG,EAAE,QAAQ,KAAK,SAAS,EAAE,gBAAgB,mBAAmB,EAAE,CAAC;AAAA,EAE/G,SAAS,OAAY;AACnB,YAAQ,MAAM,uDAAuD,KAAK;AAC1E,YAAQ,OAAO,KAAK,oBAAoB,MAAM,OAAO,EAAE;AACvD,WAAO,IAAI,SAAS,KAAK,UAAU,OAAO,GAAG,EAAE,QAAQ,KAAK,SAAS,EAAE,gBAAgB,mBAAmB,EAAE,CAAC;AAAA,EAC/G;AACF;AA7GsB;;;AClBf,IAAM,SAAS;AAAA,EACpB,MAAM;AAAA;AAAA;AAAA,IAGJ,gBAAgB;AAAA;AAAA,MAEd;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAQF;AAAA;AAAA,IAGA,eAAe;AAAA;AAAA,IAGf,kBAAkB;AAAA,EACpB;AAAA;AAAA,EAGA,WAAW;AAAA,IACT,mBAAmB;AAAA,IACnB,iBAAiB;AAAA,EACnB;AAAA;AAAA,EAGA,QAAQ;AAAA,IACN,gBAAgB,OAAO;AAAA;AAAA,IACvB,kBAAkB;AAAA,IAClB,SAAS;AAAA,EACX;AACF;;;AC9BA,IAAM,SAAS,EAAO;AAGtB,SAAS,eAAe,UAAoB,SAA4B;AACtE,QAAM,SAAS,QAAQ,QAAQ,IAAI,QAAQ;AAG3C,MAAI,UAAU,OAAO,KAAK,eAAe,SAAS,MAAM,GAAG;AACzD,aAAS,QAAQ,IAAI,+BAA+B,MAAM;AAAA,EAC5D,WAAW,CAAC,UAAU,OAAO,KAAK,eAAe;AAE/C,aAAS,QAAQ,IAAI,+BAA+B,GAAG;AAAA,EACzD;AAEA,WAAS,QAAQ,IAAI,gCAAgC,oBAAoB;AACzE,WAAS,QAAQ,IAAI,gCAAgC,2CAA2C;AAEhG,MAAI,OAAO,KAAK,kBAAkB;AAChC,aAAS,QAAQ,IAAI,oCAAoC,MAAM;AAAA,EACjE;AAEA,SAAO;AACT;AAnBS;AAsBT,OAAO,QAAQ,KAAK,CAAC,YAAY;AAC/B,SAAO,eAAe,IAAI,SAAS,MAAM,EAAE,QAAQ,IAAI,CAAC,GAAG,OAAO;AACpE,CAAC;AAKD,OAAO,IAAI,SAAS,aAAa,MAAM,IAAI,SAAS,MAAM,EAAE,QAAQ,IAAI,CAAC,CAAC;AAQ1E,OAAO,KAAK,QAAQ,aAAa,UAAU;AAI3C,OAAO,IAAI,SAAS,cAAc;AAGlC,OAAO,KAAK,WAAW,aAAa,aAAa;AAGjD,OAAO,IAAI,qBAAqB,iBAAiB;AAGjD,OAAO,IAAI,oBAAoB,iBAAiB;AAKhD,OAAO,IAAI,8BAA8B,aAAa,eAAe;AAGrE,OAAO,IAAI,KAAK,MAAM,IAAI,SAAS,aAAa,EAAE,QAAQ,IAAI,CAAC,CAAC;AAEhE,IAAO,gBAAQ;AAAA,EACb,MAAM,MAAM,SAAkB,KAAU,MAA2C;AACjF,QAAI;AACF,YAAM,WAAW,MAAM,OAAO,OAAO,SAAS,GAAG;AAEjD,aAAO,eAAe,UAAU,OAAO;AAAA,IACzC,SAAS,OAAO;AACd,cAAQ,MAAM,oBAAoB,KAAK;AACvC,YAAM,gBAAgB,IAAI,SAAS,yBAAyB,EAAE,QAAQ,IAAI,CAAC;AAC3E,aAAO,eAAe,eAAe,OAAO;AAAA,IAC9C;AAAA,EACF;AACF;",
  "names": ["e", "t", "e", "e", "e", "e"]
}
